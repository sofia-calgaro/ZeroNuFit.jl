{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15d46ac-da13-44ce-883f-5cb91395e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/LEGEND/ZeroNuFit.jl`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\") # Activate the environment\n",
    "using ArgParse\n",
    "using Logging, LoggingExtras\n",
    "using JSON\n",
    "using LegendHDF5IO\n",
    "using FilePathsBase\n",
    "using DataStructures\n",
    "using PropDicts\n",
    "using Tables\n",
    "using TypedTables\n",
    "using LegendDataManagement\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb13e46-3c52-40e4-8e66-4fc41cd16ca5",
   "metadata": {},
   "source": [
    "### Notebook to make the configs for the fit\n",
    "This should be converted to a `script.jl` all it does it reformat inputs from L-200, GERDA and Majorana into one common format readble by `ZeroNuFit.jl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10f8c0-f508-48a0-9061-b54009419b0f",
   "metadata": {},
   "source": [
    "### Events files\n",
    "First we need files containing the physics events in the three experiments.\n",
    "For L-200 these are not available to the collaboration, so we need to create the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab3c861-9a1d-4c24-b5be-bb66ce700861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String, Vector{Any}}(\"events\" => [Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1995.2452, \"timestamp\" => 1455109448, \"detector\" => \"ANG4\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1958.6807, \"timestamp\" => 1457847659, \"detector\" => \"GD61C\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2018.1346, \"timestamp\" => 1472522222, \"detector\" => \"GD35B\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1950.9419, \"timestamp\" => 1475981084, \"detector\" => \"ANG1\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2067.9735, \"timestamp\" => 1480290460, \"detector\" => \"GD35B\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2056.428, \"timestamp\" => 1485848926, \"detector\" => \"GD91A\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2042.0641, \"timestamp\" => 1503578885, \"detector\" => \"GD76C\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1962.7372, \"timestamp\" => 1509498133, \"detector\" => \"ANG1\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1957.5059, \"timestamp\" => 1516142805, \"detector\" => \"RG1\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 1970.1398, \"timestamp\" => 1533092526, \"detector\" => \"GD61C\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2058.8776, \"timestamp\" => 1539047354, \"detector\" => \"IC74A\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2015.8751, \"timestamp\" => 1566823934, \"detector\" => \"ANG4\"), Dict{String, Any}(\"experiment\" => \"GERDA\", \"energy\" => 2012.0643, \"timestamp\" => 1568276649, \"detector\" => \"GD32D\")])"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_events_gerda(file_path)\n",
    "    timestamp=[1455109448, 1457847659, 1472522222, 1475981084, 1480290460,\n",
    "                   1485848926, 1503578885, 1509498133, 1516142805, 1533092526,\n",
    "                   1539047354, 1566823934, 1568276649]\n",
    "    detector=[\"ANG4\", \"GD61C\", \"GD35B\", \"ANG1\", \"GD35B\", \"GD91A\", \"GD76C\",\n",
    "                  \"ANG1\", \"RG1\", \"GD61C\", \"IC74A\", \"ANG4\", \"GD32D\"]\n",
    "    energy=[1995.2452, 1958.6807, 2018.1346, 1950.9419, 2067.9735,\n",
    "                2056.4280, 2042.0641, 1962.7372, 1957.5059, 1970.1398,\n",
    "                2058.8776, 2015.8751, 2012.0643]\n",
    "    experiment = fill(\"GERDA\",length(energy))\n",
    "    output=Dict(\"events\" => [])\n",
    "    for (exp,t,d,e) in zip(experiment,timestamp,detector,energy)\n",
    "        append!(output[\"events\"],[Dict(\"experiment\"=>exp,\"timestamp\"=>t,\"energy\"=>e,\"detector\"=>d)])\n",
    "    end\n",
    "    open(file_path, \"w\") do file\n",
    "        write(file, json(output,4))\n",
    "    end\n",
    "end\n",
    "\n",
    "read_events_gerda(\"config/events_gerda.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da05104c-91e7-421b-9cc7-d2eafaa0047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_events_l200(file_path,meta_path)\n",
    "    files =readdir(\"data/l200/skm/phy/\")\n",
    "   \n",
    "    files=[joinpath(\"data/l200/skm/phy/\",f) for f in files]\n",
    "    \n",
    "    vsel=ValiditySelection(\"20230312T043356Z\", :phy)\n",
    "    chmap = LegendDataManagement.AnyProps(meta_path).hardware.configuration.channelmaps(vsel)\n",
    "    map = Dict( chmap[name].daq.rawid => String(name) for name in keys(chmap))\n",
    "    E_fit=[]\n",
    "    t_fit=[]\n",
    "    d_fit=[]\n",
    "    for f in files\n",
    "        data = lh5open(f)[\"skm\"][:]\n",
    "        \n",
    "        data   =data[.!data.coincident.muon_offline .&&\n",
    "            .!data.coincident.spms .&&\n",
    "            data.geds.psd.is_bb_like\n",
    "        ]\n",
    "    \n",
    "        E = data.geds.energy\n",
    "        T=  data.trigger.timestamp\n",
    "        R= data.geds.rawid\n",
    "        # cannot code a union (∪) of disjoint intervals with IntervalSets?\n",
    "        ranges =[[1930,2099],[2109,2114],[2124,2190]]\n",
    "       \n",
    "        for (e,t,ra) in zip(E,T,R)\n",
    "            for r in ranges\n",
    "                if (e<r[2] && e>r[1])\n",
    "                    append!(E_fit,e)\n",
    "                    append!(t_fit,t)\n",
    "                    append!(d_fit,[map[Int(ra)]])\n",
    "                end\n",
    "               \n",
    "             end\n",
    "        end\n",
    "  \n",
    "    end\n",
    "    blind_energy = [2040.261963,2016.760010]\n",
    "    blind_ts = [1693877463,1698552984]\n",
    "    blind_det =[\"P00661C\",\"V00048A\"]\n",
    "    append!(E_fit,blind_energy)\n",
    "    append!(t_fit,blind_ts)\n",
    "    append!(d_fit,blind_det)\n",
    "\n",
    "    output=Dict(\"events\" => [])\n",
    "    for (t,d,e) in zip(t_fit,d_fit,E_fit)\n",
    "        append!(output[\"events\"],[Dict(\"experiment\"=>\"L200\",\"timestamp\"=>t,\"energy\"=>e,\"detector\"=>d)])\n",
    "    end\n",
    "    open(file_path, \"w\") do file\n",
    "        write(file, json(output,4))\n",
    "    end\n",
    "end\n",
    "read_events_l200(\"config/events_l200.json\",\"../legend-metadata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba7aa47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14485"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_events_mjd(file_path,output_path)\n",
    "\n",
    "\n",
    "    E_fit=[]\n",
    "    t_fit=[]\n",
    "    d_fit=[]\n",
    "    ranges =[[1930,2099],[2109,2114],[2124,2190]]\n",
    "\n",
    "    open(file_path, \"r\") do file\n",
    "    \n",
    "        for line in eachline(file)\n",
    "            ls=split(line,\" \")\n",
    "            name = ls[1]\n",
    "            ts=parse(Int,ls[2])\n",
    "            energy =parse(Float64,ls[3])\n",
    "            bkg = ls[4]\n",
    "            for r in ranges\n",
    "                if (energy<r[2] && energy>r[1])\n",
    "                    append!(E_fit,energy)\n",
    "                    append!(t_fit,ts)\n",
    "                    append!(d_fit,[name])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "   \n",
    "    output=Dict(\"events\" => [])\n",
    "    for (t,d,e) in zip(t_fit,d_fit,E_fit)\n",
    "        append!(output[\"events\"],[Dict(\"experiment\"=>\"MJD\",\"timestamp\"=>t,\"energy\"=>e,\"detector\"=>d)])\n",
    "    end\n",
    "    open(output_path, \"w\") do file\n",
    "        write(file, json(output,4))\n",
    "    end\n",
    "end\n",
    "read_events_mjd(\"data/mjd/events.txt\",\"config/events_mjd_new_part.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53497536-b973-4655-a520-e547d3c77233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AB\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str=\"ABC\"\n",
    "str[1]*str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23181b69-e7da-4d52-98a8-469c701681b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gerda_name_to_type (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gerda_name_to_type(name)\n",
    "    if (name[1]*name[2]==\"GD\")\n",
    "        return \"BG\"\n",
    "    elseif (name[1]*name[2]==\"RG\" || name[1]*name[2]==\"AN\")\n",
    "        return \"SC\"\n",
    "    elseif (name[1]*name[2]==\"IC\")\n",
    "        return \"IC\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62871392-eb8e-438c-93eb-306146b6f951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IC\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerda_name_to_type(\"IC11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32267068-4524-4f9b-a3a3-df18a191aab2",
   "metadata": {},
   "source": [
    "### Partitions files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec3bb725-a279-4638-bb80-9213c1baa95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_partitions_file_gerda (generic function with 2 methods)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_partitions_file_gerda(input_path,output_path,by_type=false)\n",
    "    json_data = JSON.parsefile(input_path,dicttype=DataStructures.OrderedDict)\n",
    "\n",
    "    if (by_type==false)\n",
    "        fit_groups=Dict(\"all_phase_II\"=>Dict(\"range\"=>[[1930,2099],[2109,2114],[2124,2190]],\"model\"=>\"uniform\",\n",
    "            \"bkg_name\"=>\"B_gerda_all_pII\"))\n",
    "    else\n",
    "        fit_groups=Dict()\n",
    "        for dettype in [\"BG\",\"IC\",\"SC\"]\n",
    "            fit_groups[\"$(dettype)_phase_II\"]=Dict(\"range\"=>[[1930,2099],[2109,2114],[2124,2190]],\"model\"=>\"uniform\",\n",
    "            \"bkg_name\"=>\"B_gerda_$(dettype)_pII\")\n",
    "        end\n",
    "    end\n",
    "    partitions_full=Dict()\n",
    "    for group in keys(fit_groups)\n",
    "        partitions_full[group]=[]\n",
    "        counter=0\n",
    "        for (part,part_data) in sort(json_data)\n",
    "            part_name = String(\"part\")*@sprintf(\"%02d\", counter)\n",
    "            counter+=1\n",
    "            println(part_name)\n",
    "            for (det,info) in json_data[part]\n",
    "                if (info isa OrderedDict)\n",
    "                    if (by_type && gerda_name_to_type(det)!=group[1]*group[2])\n",
    "                        continue\n",
    "                    end\n",
    "                    part_temp = OrderedDict(\"experiment\"=>\"GERDA\",\"detector\"=> det,\n",
    "                                    \"part_name\"=>part_name,\n",
    "                                     \"start_ts\"=>json_data[part][\"start_ts\"],\n",
    "                                     \"end_ts\"=>json_data[part][\"end_ts\"])\n",
    "                    copy_fields=[\"eff_tot\",\"eff_tot_sigma\",\"fwhm\",\"fwhm_sigma\",\"exposure\",\"bias\"]\n",
    "                    for field in copy_fields\n",
    "                        part_temp[field]=json_data[part][det][field]\n",
    "                    end\n",
    "                       \n",
    "                    part_temp[\"bias_sigma\"]=json_data[part][det][\"energy_sigma\"]\n",
    "                    append!(partitions_full[group],[part_temp])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    output=Dict(\"fit_groups\"=>fit_groups,\n",
    "                \"partitions\"=>partitions_full)\n",
    "    \n",
    "    open(output_path, \"w\") do file\n",
    "        write(file, json(output,4))\n",
    "      \n",
    "    end\n",
    "                \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a7797d5-b0b8-483e-a1c1-317edd11554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part00\n",
      "part01\n",
      "part02\n",
      "part03\n",
      "part04\n",
      "part05\n",
      "part06\n",
      "part07\n",
      "part08\n",
      "part09\n",
      "part10\n",
      "part00\n",
      "part01\n",
      "part02\n",
      "part03\n",
      "part04\n",
      "part05\n",
      "part06\n",
      "part07\n",
      "part08\n",
      "part09\n",
      "part10\n",
      "part00\n",
      "part01\n",
      "part02\n",
      "part03\n",
      "part04\n",
      "part05\n",
      "part06\n",
      "part07\n",
      "part08\n",
      "part09\n",
      "part10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "201423"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_partitions_file_gerda(\"/home/tdixon/Downloads/0vbb-analysis-parameters.json\",\"config/partitions_gerda_by_type.json\",true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb2f8c9-558e-4399-887b-49c671899540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printdb (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function printdb(db)\n",
    "        if db isa PropDict\n",
    "            for (key,value) in db\n",
    "                println(key)\n",
    "                printdb(value)\n",
    "            end\n",
    "        else\n",
    "            println(\"\\t\",db)\n",
    "            println()\n",
    "        end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f845fa4a-169b-4694-9c1a-60a9523b384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"@\"\n",
       " \"@v#.#\"\n",
       " \"@stdlib\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sys.BINDIR\n",
    "Pkg.envdir()\n",
    "Base.active_project()\n",
    "LOAD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9be63213-a9ad-4dc1-952a-8935850075b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_partitions_file_l200 (generic function with 1 method)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_partitions_file_l200(meta_path,output_path)\n",
    "\n",
    "    meta = LegendDataManagement.AnyProps(meta_path)\n",
    "\n",
    "    partitions = meta.datasets.ovbb_partitions_pars\n",
    "    printflag=false\n",
    "    output=[]\n",
    "    # loop over detectors\n",
    "    for (detector, detdata) in partitions\n",
    "        if detector == :default\n",
    "            continue\n",
    "        end\n",
    "\n",
    "      \n",
    "        \n",
    "        # apply defaults\n",
    "        if partitions.default isa PropDicts.MissingProperty \n",
    "            detdata_merge = copy(detdata)\n",
    "        else\n",
    "            new = partitions.default\n",
    "            detdata_merge = merge(new,copy(detdata))\n",
    "        end\n",
    "        \n",
    "        # loop over partitions for this detector\n",
    "        for (partition, pardata) in detdata_merge\n",
    "            if partition == :default\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            if detdata_merge.default isa PropDicts.MissingProperty \n",
    "                pardata_merge = copy(pardata)\n",
    "            else\n",
    "                new = detdata_merge.default\n",
    "                pardata_merge = merge(new,copy(pardata))\n",
    "            end\n",
    "\n",
    "            if printflag == true\n",
    "                println(\"for partition $partition \")\n",
    "                #printdb(pardata_merge)\n",
    "                println(\"\\n\")\n",
    "            end\n",
    "            part_temp = OrderedDict(\"experiment\"=>\"L200\",\"detector\"=> detector,\"part_name\"=>partition,\n",
    "                                 \"start_ts\"=>pardata_merge[:span_in_utc_s][1],\n",
    "                                 \"end_ts\"=>pardata_merge[:span_in_utc_s][2])\n",
    "            eff = prod([v[:val] for v in values(pardata_merge[:ovbb_acceptance])])\n",
    "            eff_sigma = √(sum([v[:unc] for v in values(pardata_merge[:ovbb_acceptance])].^2))    \n",
    "\n",
    "            # include the enrichment\n",
    "            eff*=           meta.hardware.detectors.germanium.diodes[detector].production.enrichment.val\n",
    "            enrichment_err =meta.hardware.detectors.germanium.diodes[detector].production.enrichment.unc\n",
    "\n",
    "            eff_sigma=√(eff_sigma^2+enrichment_err^2)\n",
    "\n",
    "            part_temp[\"eff_tot\"]=eff\n",
    "            part_temp[\"eff_tot_sigma\"]=eff_sigma\n",
    "            part_temp[\"fwhm\"]=pardata_merge[:fwhm_in_keV][:val]\n",
    "            part_temp[\"fwhm_sigma\"]=pardata_merge[:fwhm_in_keV][:unc]\n",
    "            part_temp[\"exposure\"]=pardata_merge[:livetime_in_s]*\n",
    "                meta.hardware.detectors.germanium.diodes[detector].production.mass_in_g/(60*60*24*365.25*1000)\n",
    "            part_temp[\"bias\"]=pardata_merge[:energy_bias_in_keV][:val]\n",
    "            part_temp[\"bias_sigma\"]=pardata_merge[:energy_bias_in_keV][:unc]\n",
    "\n",
    "            append!(output,[part_temp])\n",
    "\n",
    "        end\n",
    "    end\n",
    "    output_full=Dict(\"fit_groups\"=>Dict(\"l200a\"=>Dict(\"range\"=>[[1930,2099],[2109,2114],[2124,2190]],\"model\"=>\"uniform\")),\n",
    "                \"partitions\"=>Dict(\"l200a\"=>output))\n",
    "    open(output_path, \"w\") do file\n",
    "        write(file, json(output_full,4))\n",
    "       \n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f800353-961e-4115-be17-38f56a12870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154015"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_partitions_file_l200(\"../legend-metadata\",\"config/partitions_l200.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c313166c-27e4-4c09-a517-19511fb6ac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_partitions_mjd (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_partitions_mjd(input_path,output_path)\n",
    "\n",
    "    \n",
    "    \n",
    "    fit_groups=[\"mjd-DS0\",\"mjd-mod1\",\"mjd-mod2\"]\n",
    "    partitions=OrderedDict()\n",
    "    for fit in fit_groups\n",
    "        partitions[fit]=[]\n",
    "    end\n",
    "    keywords =[\"detnum\",\"detector\",\"fwhm\",\"fwhm_sigma\",\"eff_tot\",\"eff_tot_sigma\",\"exposure\",\"bias\",\"bias_sigma\",\"bkgname\",\"sysname\"]\n",
    "    \n",
    "    open(input_path, \"r\") do file\n",
    "        time_start=0\n",
    "        time_end=0\n",
    "        for line in eachline(file)\n",
    "            if startswith(line,\"t\")\n",
    "                ts = split(line,\" \")\n",
    "                time_start = parse(Int,ts[2])\n",
    "                time_end = parse(Int,ts[3])\n",
    "                continue\n",
    "            else\n",
    "                info = split(line,\" \")\n",
    "                info_dict=Dict()\n",
    "                for (id,key) in enumerate(keywords)\n",
    "                    info_dict[key]=info[id]\n",
    "                end\n",
    "            end\n",
    "            fit_group=info_dict[\"bkgname\"]\n",
    "            if (time_start==1000)\n",
    "                part_name=\"first-ds\"\n",
    "            else\n",
    "                part_name=\"other-ds\"\n",
    "            end\n",
    "            part_temp=OrderedDict(\"experiment\"=>\"MJD\",\"detector\"=>info_dict[\"detector\"],\n",
    "                \"part_name\"=>part_name,\n",
    "                \"start_ts\"=>time_start,\"end_ts\"=>time_end,\n",
    "                \"eff_tot\"=>parse(Float64,info_dict[\"eff_tot\"]), \"eff_tot_sigma\"=>parse(Float64,info_dict[\"eff_tot_sigma\"]),\n",
    "                \"fwhm\"=>parse(Float64,info_dict[\"fwhm\"]), \"fwhm_sigma\"=>parse(Float64,info_dict[\"fwhm_sigma\"]),\n",
    "                \"exposure\"=>parse(Float64,info_dict[\"exposure\"]),\n",
    "                 \"bias\"=>parse(Float64,info_dict[\"bias\"]), \"bias_sigma\"=>parse(Float64,info_dict[\"bias_sigma\"]))\n",
    "\n",
    "            append!(partitions[fit_group],[part_temp])\n",
    "\n",
    "\n",
    "            \n",
    "        end\n",
    "    \n",
    "        fit_groups_dict=Dict()\n",
    "        for fit in fit_groups\n",
    "            fit_groups_dict[fit]=Dict(\"bkg_name\"=>fit,\"range\"=>[[1930,2099],[2109,2114],[2124,2190]],\"model\"=>\"uniform\")\n",
    "        end\n",
    "\n",
    "        output=Dict(\"fit_groups\"=>fit_groups_dict,\"partitions\"=>partitions)\n",
    "        open(output_path, \"w\") do file\n",
    "            write(file, json(output,4))\n",
    "        end\n",
    "    end    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ba00c6-2d10-4c80-9787-052fd71ef77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_partitions_mjd(\"data/mjd/parameter.txt\",\"config/partitions_mjd_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c579c-8842-497b-a4d8-18fca3a93c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
